import os
import pandas as pd
from pybtex.database import parse_file
from bib_dedupe.bib_dedupe import prep, block, match, cluster, merge

# ğŸ”¹ æ–‡ä»¶è·¯å¾„
BIB_FILE_PATH = "/Users/jiangmingxin/Desktop/bib-dedupe-1/notebooks/PDF_DBLP_title_samples.bib"
CSV_FILE_PATH = "/Users/jiangmingxin/Desktop/bib-dedupe-1/output/PDF_DBLP_title_samples.csv"
OUTPUT_CSV_PATH = "/Users/jiangmingxin/Desktop/bib-dedupe-1/output/PDF_DBLP_title_samples_deduped.csv"

# ğŸ”¹ ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(os.path.dirname(CSV_FILE_PATH), exist_ok=True)

# ğŸ”¹ è®¾å®šè¦æå–çš„å­—æ®µ
FIELDS_TO_KEEP = ["ID", "author", "title", "year", "journal", "doi"]

def convert_bib_to_csv():
    """è½¬æ¢ BibTeX æ–‡ä»¶åˆ° CSV"""
    print(f"ğŸ”„ æ­£åœ¨è½¬æ¢ {BIB_FILE_PATH} åˆ° CSV...")
    bib_data = parse_file(BIB_FILE_PATH)
    records = []
    
    for key, entry in bib_data.entries.items():
        record = {field: entry.fields.get(field, "") for field in FIELDS_TO_KEEP}
        
        # å¤„ç†ä½œè€…å­—æ®µ
        if "author" in entry.persons:
            record["author"] = " and ".join(
                [" ".join(person.first_names + person.last_names) for person in entry.persons["author"]]
            )

        # è®¾å®šå”¯ä¸€ ID
        record["ID"] = key
        records.append(record)

    # è½¬æ¢ä¸º DataFrame
    df = pd.DataFrame(records)

    # å¤„ç†ç©ºå€¼ï¼ˆé¿å… BibDedupe å¿½ç•¥ï¼‰
    df.fillna("", inplace=True)

    # ä¿å­˜ä¸º CSV
    df.to_csv(CSV_FILE_PATH, index=False)
    print(f"âœ… CSV æ–‡ä»¶å·²åˆ›å»º: {CSV_FILE_PATH}")

def run_dedupe():
    """è¿è¡Œ BibDedupe å»é‡"""
    print(f"\nğŸš€ è¿è¡Œå»é‡ç®—æ³•...")
    df = pd.read_csv(CSV_FILE_PATH)
    print(f"ğŸ“Œ åŸå§‹æ•°æ®é›†å¤§å°: {df.shape[0]} æ¡")

    # é¢„å¤„ç†æ•°æ®
    df = prep(df)

    # è¿›è¡Œ blocking ä»¥å‡å°‘è®¡ç®—é‡
    blocked_df = block(df)

    # è¿›è¡ŒåŒ¹é…ï¼Œæ‰¾åˆ°å¯èƒ½çš„é‡å¤é¡¹
    matched_df = match(blocked_df)

    # è¿›è¡Œèšç±»ï¼Œå°†é‡å¤é¡¹å½’ç±»åˆ°ä¸€èµ·
    duplicate_id_sets = cluster(matched_df)

    # æ‰§è¡Œåˆå¹¶ï¼Œç§»é™¤é‡å¤é¡¹
    deduped_df = merge(df, duplicate_id_sets=duplicate_id_sets)

    # ä¿å­˜å»é‡åçš„ç»“æœ
    deduped_df.to_csv(OUTPUT_CSV_PATH, index=False)
    print(f"âœ… å»é‡åæ•°æ®é›†å·²ä¿å­˜: {OUTPUT_CSV_PATH}")

    # æŸ¥çœ‹å»é‡ç»“æœ
    print(f"ğŸ“Œ å»é‡åæ•°æ®é›†å¤§å°: {deduped_df.shape[0]} æ¡")
    print(deduped_df.head())

if __name__ == "__main__":
    convert_bib_to_csv()  # æ­¥éª¤ 1: è½¬æ¢ CSV
    run_dedupe()          # æ­¥éª¤ 2: è¿è¡Œå»é‡
